# -*- coding: utf-8 -*-
# Generated by Django 1.11.13 on 2018-07-12 13:28
from __future__ import unicode_literals

from collections import Iterable

from bulk_update.helper import bulk_update
from django.db import migrations
from six.moves import xrange

from radaro_utils import compat, helpers

chunk_size = 50


# Migrating bulk's data about csv file to CSVOrders file
# Migrating bulk's instances and errors to separate OrderPrototype models
def migrate_data(apps, schema_migration):
    CSVOrdersFile = apps.get_model('tasks.CSVOrdersFile')
    BulkDelayedUpload = apps.get_model('tasks.BulkDelayedUpload')
    OrderPrototype = apps.get_model('tasks.OrderPrototype')
    uploads = BulkDelayedUpload.objects.all()
    for chunk in helpers.chunks(uploads, length=uploads.count(), n=chunk_size):
        files = []
        for bulk in chunk:
            exclude_line_numbers = set()
            errors = []
            if isinstance(bulk.data, Iterable):
                for error in bulk.data:
                    exclude_line_numbers.add(error['index'])
                    errors.append(OrderPrototype(errors=error['data'], line=error['index'], processed=True, bulk=bulk))
            if not bulk.instances:
                bulk.instances = []
            line_generator = (x for x in xrange(len(errors + bulk.instances)) if x not in exclude_line_numbers)
            all_prototypes = errors + [OrderPrototype(content=x, line=line, processed=True, bulk=bulk)
                                       for x, line in zip(bulk.instances, line_generator)]
            state = bulk.state_params or {}
            params = {
                'encoding': state.get('encoding', bulk.encoding) or 'utf-8',
                'lines': state.get('lines', bulk.lines) or 0,
                'file': bulk.file,
                'original_file_name': bulk.original_file_name,
                'bulk': bulk,
            }
            blank_lines = params['lines'] - len(all_prototypes) - 1
            params['blank_lines'] = blank_lines if blank_lines > 0 else 0
            files.append(CSVOrdersFile(
                encoding=params.pop('encoding').lower(),
                **params
            ))
            OrderPrototype.objects.bulk_create(all_prototypes)
        CSVOrdersFile.objects.bulk_create(files)


def migrate_data_back(apps, schema_migration):
    CSVOrdersFile = apps.get_model('tasks.CSVOrdersFile')
    file_uploads = CSVOrdersFile.objects.select_related('bulk').all()
    for chunk in helpers.chunks(file_uploads, length=file_uploads.count(), n=chunk_size):
        bulks = []
        for file_obj in chunk:
            bulk = file_obj.bulk
            bulk.data = [{'index': o_p.line, 'data': o_p.errors} for o_p in bulk.prototypes.exclude(errors='')]
            bulk.instances = [o_p.content for o_p in bulk.prototypes.filter(errors='')]
            bulk.state_params = {
                'saved': len(bulk.instances) if bulk.status == 'confirmed' else 0,
                'processed': len(bulk.instances) + len(bulk.data),
                'errors_found': len(bulk.data),
                'encoding': file_obj.encoding.upper(),
                'lines': file_obj.lines
            }
            bulk.file = file_obj.file
            bulk.original_file_name = file_obj.original_file_name
            bulks.append(bulk)
        bulk_update(bulks, update_fields=['data', 'instances', 'state_params', 'file', 'original_file_name'])


class Migration(migrations.Migration):

    dependencies = [
        ('tasks', '0117_auto_20180712_2303_1'),
    ]

    operations = [
        migrations.RunPython(code=migrate_data, reverse_code=migrate_data_back)
    ]
